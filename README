反爬虫机制
在开始写知乎的爬虫文档之前，我们先来看看知乎的反爬虫机制。
1 知乎在未登录的情况下使不能通过浏览器进行页面加载的，既我们所谓的ajax
2 知乎在未登录的情况下不能看到问题的浏览人次
3 不携带浏览器头部返回500
4 频繁抓取封ip

需求
在开始屑爬虫之前 我们也要明确自己的需求
对于问题评论 答案的id号 答案的点赞数 答案的发布时间 答案的评论数 答案正文
对于问题 问题id 问题名称 问题浏览人次 问题答案数量
对于话题 抓取输入艺人的话题下所有问题名称 匹配关键字决定是否需要抓取答案
话题———问题———需要抓取问题——答案列表——答案详情并入库

spider接口
spider是主要的爬虫类 定义了两个对外接口 一个是debug 用来通过问题的id爬取答案信息存入数据库，这里是mysql数据库
另一个是get topic  通过姓名与话题id爬取该话题下所有符合要求的问题id存放到temp  ques_link中。

spider函数
1 对于话题这部分来说，一个比较重要的函数是load_next_page，这个函数用来加载知乎的下一页信息。
知乎的信息加载用的是post方式，返回的是加载部分的html， 前面已经提到没有headers知乎是不会返回给你数据的,不过幸运的是虽然在浏览器中
无登陆不能下拉加载，但在代码是可以实现模拟的，通过post提交headers和data。headers种的x-xsrftoken值取自该话题链接中的最后，(start_crawl_topic
中 get_token) 而data中的offset则是定义了加载下一批数据的起始位置。隐藏在上一批数据中。拿到即可，而第一次加载只需将其置为None。

2 注意如果出现ssl证书问题，只需将requests中的verify=False即可。

3 之前说的浏览人次，在未登录时隐藏在源代码中，这个在extract_question_profile函数中有体现，即为looked

4使用代理一定要将api设置为高匿，透明代理是不管用的。其余的问题大家看代码吧